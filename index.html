<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chroma Key con TensorFlow.js y BodyPix</title>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
        }

        video, canvas {
            width: 80%;
            max-width: 600px;
            border: 2px solid #000;
            border-radius: 8px;
        }

        #background {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }
    </style>
</head>
<body>
    <h1>Chroma Key con TensorFlow.js y BodyPix</h1>
    <video id="video" autoplay playsinline></video>
    <canvas id="output"></canvas>
    
    <!-- Fondo personalizado (puede ser una imagen o color) -->
    <img id="background" src="https://example.com/tu-imagen-de-fondo.jpg" alt="Fondo">

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>
    <script>
        const videoElement = document.getElementById('video');
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d');

        // Cargar el modelo BodyPix
        async function loadBodyPix() {
            return await bodyPix.load();
        }

        // Obtener acceso a la cámara web
        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            videoElement.srcObject = stream;

            return new Promise((resolve) => {
                videoElement.onloadedmetadata = () => {
                    resolve(videoElement);
                };
            });
        }

        // Iniciar el proceso de detección
        async function start() {
            const net = await loadBodyPix();
            await setupCamera();

            videoElement.play();

            // Definir parámetros para la segmentación
            const segmentationConfig = {
                flipHorizontal: false,  // No invertir el video
                internalResolution: 'medium',  // Precisión de la segmentación
                segmentationThreshold: 0.7  // Sensibilidad de la segmentación
            };

            function segmentPerson() {
                net.segmentPerson(videoElement, segmentationConfig).then((segmentation) => {
                    // Dibujar la segmentación sobre el canvas
                    const maskBackground = bodyPix.toMask(segmentation);
                    const videoWidth = videoElement.videoWidth;
                    const videoHeight = videoElement.videoHeight;

                    canvas.width = videoWidth;
                    canvas.height = videoHeight;

                    // Renderizar el cuerpo de la persona en el canvas
                    ctx.putImageData(maskBackground, 0, 0);

                    // Continuar segmentando en tiempo real
                    requestAnimationFrame(segmentPerson);
                });
            }

            // Comenzar la segmentación
            segmentPerson();
        }

        // Ejecutar el código
        start();
    </script>
</body>
</html>
